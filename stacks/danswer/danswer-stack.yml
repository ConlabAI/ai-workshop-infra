version: '3'
services:

  # Presentation layer
  web_server:
    image: danswer/danswer-web-server:latest
    depends_on:
      - api_server
    restart: always
    env_file:
      - .env
    environment:
      - INTERNAL_URL=http://api_server:8080
    networks:
      - public_network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.front.rule=Path('/')"
      - "traefik.http.routers.front.entrypoints=web"
      - "traefik.http.services.front.loadbalancer.server.port=3000"
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  # Application layer
  api_server:
    image: danswer/danswer-backend:latest
    command: >
      /bin/sh -c "alembic upgrade head &&
      echo \"Starting Danswer Api Server\" &&
      uvicorn danswer.main:app --host 0.0.0.0 --port 8080"
    depends_on:
      - relational_db
      - index
      - inference_model_server
    restart: always
    env_file:
      - .env
    environment:
      - AUTH_TYPE=${AUTH_TYPE:-google_oauth}
      - POSTGRES_HOST=relational_db
      - VESPA_HOST=index
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-inference_model_server}
    networks:
      - public_network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=PathRegexp('^/(api|openapi.json)(/.*)?$$')"
      - "traefik.http.routers.api.entrypoints=web"
      - "traefik.http.routers.api.middlewares=strip-api"
      - "traefik.http.middlewares.strip-api.stripprefix.prefixes=/api"
      - "traefik.http.services.api.loadbalancer.server.port=8080"
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  background:
    image: danswer/danswer-backend:latest
    command: /usr/bin/supervisord
    depends_on:
      - relational_db
      - index
      - inference_model_server
      - indexing_model_server
    restart: always
    env_file:
      - .env
    environment:
      - AUTH_TYPE=${AUTH_TYPE:-google_oauth}
      - POSTGRES_HOST=relational_db
      - VESPA_HOST=index
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-inference_model_server}
      - INDEXING_MODEL_SERVER_HOST=${INDEXING_MODEL_SERVER_HOST:-indexing_model_server}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - public_network
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  # Data layer
  relational_db:
    image: postgres:15.2-alpine
    restart: always
    env_file:
      - .env
    volumes:
      - db_volume:/var/lib/postgresql/data
    networks:
      - public_network
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  index:
    image: vespaengine/vespa:8.277.17
    restart: always
    volumes:
      - vespa_volume:/opt/vespa/var
    networks:
      - public_network
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  inference_model_server:
    image: danswer/danswer-model-server:latest
    command: >
      /bin/sh -c "if [ \"${DISABLE_MODEL_SERVER:-false}\" = \"True\" ]; then
        echo 'Skipping service...';
        exit 0;
      else
        exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000;
      fi"
    restart: on-failure
    environment:
      - MIN_THREADS_ML_MODELS=${MIN_THREADS_ML_MODELS:-}
      # Set to debug to get more fine-grained logs
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Not necessary, this is just to reduce download time during startup
      - model_cache_huggingface:/root/.cache/huggingface/
    networks:
      - public_network
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  indexing_model_server:
    image: danswer/danswer-model-server:latest
    command: >
      /bin/sh -c "if [ \"${DISABLE_MODEL_SERVER:-false}\" = \"True\" ]; then
        echo 'Skipping service...';
        exit 0;
      else
        exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000;
      fi"
    restart: on-failure
    environment:
      - MIN_THREADS_ML_MODELS=${MIN_THREADS_ML_MODELS:-}
      - INDEXING_ONLY=True
      # Set to debug to get more fine-grained logs
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Not necessary, this is just to reduce download time during startup
      - model_cache_huggingface:/root/.cache/huggingface/
    networks:
      - public_network
    deploy:
      mode: replicated
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


volumes:
  db_volume:
  vespa_volume:
  model_cache_huggingface:


networks:
  public_network:
    external: true